{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f968e9-621b-4b52-914c-5f857fecdc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from textblob import TextBlob\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. Initialize Sentiment Analyzers\n",
    "def setup_analyzers():\n",
    "    \"\"\"Initialize TextBlob and DistilBERT analyzers\"\"\"\n",
    "    try:\n",
    "        print(\"Initializing sentiment analyzers...\")\n",
    "        # TextBlob doesn't need initialization\n",
    "        distilbert = pipeline(\n",
    "            \"sentiment-analysis\",\n",
    "            model=\"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "        )\n",
    "        return distilbert\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing analyzers: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82229ba2-b4a2-40a0-a760-c6f4af9dbd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Sentiment Analysis Functions\n",
    "def analyze_with_textblob(text):\n",
    "    \"\"\"Get TextBlob sentiment scores\"\"\"\n",
    "    analysis = TextBlob(text)\n",
    "    return {\n",
    "        'textblob_polarity': analysis.sentiment.polarity,\n",
    "        'textblob_subjectivity': analysis.sentiment.subjectivity,\n",
    "        'textblob_sentiment': 'positive' if analysis.sentiment.polarity > 0 \n",
    "                             else 'negative' if analysis.sentiment.polarity < 0 \n",
    "                             else 'neutral'\n",
    "    }\n",
    "\n",
    "def analyze_with_distilbert(text, analyzer):\n",
    "    \"\"\"Get DistilBERT sentiment scores\"\"\"\n",
    "    try:\n",
    "        result = analyzer(text[:512])[0]  # Truncate to model limit\n",
    "        return {\n",
    "            'distilbert_score': result['score'],\n",
    "            'distilbert_sentiment': result['label'].lower()\n",
    "        }\n",
    "    except:\n",
    "        return {\n",
    "            'distilbert_score': 0.5,\n",
    "            'distilbert_sentiment': 'neutral'\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1e904b5-8389-4afd-8c79-18cb1fae039f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Main Analysis Function\n",
    "def analyze_reviews(input_file='cleaned_reviews.csv'):\n",
    "    \"\"\"Run complete sentiment analysis pipeline\"\"\"\n",
    "    # File validation\n",
    "    if not os.path.exists(input_file):\n",
    "        print(f\"Error: File {os.path.abspath(input_file)} not found\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Load data\n",
    "        df = pd.read_csv(input_file)\n",
    "        print(f\"✅ Loaded {len(df)} reviews from {input_file}\")\n",
    "        \n",
    "        # Initialize analyzer\n",
    "        distilbert = setup_analyzers()\n",
    "        if distilbert is None:\n",
    "            return None\n",
    "        \n",
    "        # Analyze each review\n",
    "        results = []\n",
    "        print(\"Analyzing sentiments...\")\n",
    "        for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "            text = str(row.get('clean_review', row.get('review', '')))\n",
    "            if not text.strip():\n",
    "                continue\n",
    "                \n",
    "            # Get TextBlob results\n",
    "            textblob_results = analyze_with_textblob(text)\n",
    "            \n",
    "            # Get DistilBERT results\n",
    "            distilbert_results = analyze_with_distilbert(text, distilbert)\n",
    "            \n",
    "            # Combine results\n",
    "            results.append({\n",
    "                **row.to_dict(),\n",
    "                **textblob_results,\n",
    "                **distilbert_results\n",
    "            })\n",
    "        \n",
    "        # Create analyzed DataFrame\n",
    "        analyzed_df = pd.DataFrame(results)\n",
    "        \n",
    "        # Save results\n",
    "        output_file = 'analyzed_reviews.csv'\n",
    "        analyzed_df.to_csv(output_file, index=False)\n",
    "        print(f\"✅ Saved {len(analyzed_df)} analyzed reviews to {output_file}\")\n",
    "        return analyzed_df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Analysis failed: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3baeabbf-7403-4d29-a64d-5459899ec74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Aggregation Function\n",
    "def aggregate_sentiments(analyzed_df):\n",
    "    \"\"\"Aggregate by bank and rating\"\"\"\n",
    "    if analyzed_df is None or len(analyzed_df) == 0:\n",
    "        return None\n",
    "    \n",
    "    print(\"\\nAggregating results by bank and rating...\")\n",
    "    \n",
    "    # Define aggregations\n",
    "    aggregations = {\n",
    "        'textblob_polarity': ['mean', 'count'],\n",
    "        'distilbert_score': ['mean'],\n",
    "        'textblob_sentiment': lambda x: x.value_counts().to_dict(),\n",
    "        'distilbert_sentiment': lambda x: x.value_counts().to_dict()\n",
    "    }\n",
    "    \n",
    "    # Filter for only existing columns\n",
    "    available_cols = [col for col in aggregations.keys() if col in analyzed_df.columns]\n",
    "    aggregations = {col: aggregations[col] for col in available_cols}\n",
    "    \n",
    "    if not aggregations:\n",
    "        print(\"No sentiment metrics available for aggregation\")\n",
    "        return None\n",
    "    \n",
    "    # Group and aggregate\n",
    "    grouped = analyzed_df.groupby(['bank', 'rating']).agg(aggregations)\n",
    "    \n",
    "    # Flatten multi-index columns\n",
    "    grouped.columns = ['_'.join(col).strip() for col in grouped.columns.values]\n",
    "    \n",
    "    # Save and return\n",
    "    grouped.to_csv('aggregated_sentiments.csv')\n",
    "    print(\"✅ Saved aggregated results to aggregated_sentiments.csv\")\n",
    "    return grouped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22b20a63-182a-44f8-a1ed-e000bdcaf2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 987 reviews from cleaned_reviews.csv\n",
      "Initializing sentiment analyzers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing sentiments...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 987/987 [00:47<00:00, 20.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 987 analyzed reviews to analyzed_reviews.csv\n",
      "\n",
      "Aggregating results by bank and rating...\n",
      "✅ Saved aggregated results to aggregated_sentiments.csv\n",
      "\n",
      "Sample Aggregated Results:\n",
      "               textblob_polarity_mean  textblob_polarity_count  \\\n",
      "bank   rating                                                    \n",
      "BOA    1                    -0.092426                      162   \n",
      "       2                     0.078333                       10   \n",
      "       3                     0.079761                       26   \n",
      "       4                     0.194597                       13   \n",
      "       5                     0.301560                      116   \n",
      "CBE    1                    -0.036426                       46   \n",
      "       2                     0.087803                       14   \n",
      "       3                     0.107333                       18   \n",
      "       4                     0.362444                       37   \n",
      "       5                     0.397172                      206   \n",
      "Dashen 1                     0.092545                       33   \n",
      "       2                     0.005308                       17   \n",
      "       3                     0.256278                       12   \n",
      "       4                     0.236905                       17   \n",
      "       5                     0.377938                      260   \n",
      "\n",
      "               distilbert_score_mean  \\\n",
      "bank   rating                          \n",
      "BOA    1                    0.966230   \n",
      "       2                    0.936817   \n",
      "       3                    0.970595   \n",
      "       4                    0.947929   \n",
      "       5                    0.939139   \n",
      "CBE    1                    0.967109   \n",
      "       2                    0.975257   \n",
      "       3                    0.936445   \n",
      "       4                    0.927988   \n",
      "       5                    0.966303   \n",
      "Dashen 1                    0.981686   \n",
      "       2                    0.944834   \n",
      "       3                    0.948759   \n",
      "       4                    0.937687   \n",
      "       5                    0.960113   \n",
      "\n",
      "                                   textblob_sentiment_<lambda>  \\\n",
      "bank   rating                                                    \n",
      "BOA    1       {'negative': 62, 'neutral': 55, 'positive': 45}   \n",
      "       2          {'neutral': 6, 'positive': 3, 'negative': 1}   \n",
      "       3        {'neutral': 12, 'positive': 11, 'negative': 3}   \n",
      "       4                         {'neutral': 7, 'positive': 6}   \n",
      "       5        {'positive': 58, 'neutral': 55, 'negative': 3}   \n",
      "CBE    1       {'neutral': 21, 'positive': 13, 'negative': 12}   \n",
      "       2          {'positive': 7, 'negative': 4, 'neutral': 3}   \n",
      "       3         {'neutral': 11, 'positive': 6, 'negative': 1}   \n",
      "       4        {'positive': 26, 'neutral': 10, 'negative': 1}   \n",
      "       5       {'positive': 133, 'neutral': 70, 'negative': 3}   \n",
      "Dashen 1       {'positive': 12, 'negative': 11, 'neutral': 10}   \n",
      "       2          {'negative': 7, 'positive': 5, 'neutral': 5}   \n",
      "       3          {'positive': 9, 'negative': 2, 'neutral': 1}   \n",
      "       4                        {'positive': 10, 'neutral': 7}   \n",
      "       5       {'positive': 212, 'neutral': 44, 'negative': 4}   \n",
      "\n",
      "                   distilbert_sentiment_<lambda>  \n",
      "bank   rating                                     \n",
      "BOA    1       {'negative': 135, 'positive': 27}  \n",
      "       2          {'negative': 9, 'positive': 1}  \n",
      "       3        {'positive': 13, 'negative': 13}  \n",
      "       4          {'positive': 7, 'negative': 6}  \n",
      "       5        {'positive': 84, 'negative': 32}  \n",
      "CBE    1        {'negative': 30, 'positive': 16}  \n",
      "       2         {'negative': 11, 'positive': 3}  \n",
      "       3         {'negative': 12, 'positive': 6}  \n",
      "       4        {'positive': 24, 'negative': 13}  \n",
      "       5       {'positive': 169, 'negative': 37}  \n",
      "Dashen 1        {'negative': 23, 'positive': 10}  \n",
      "       2         {'negative': 14, 'positive': 3}  \n",
      "       3          {'negative': 7, 'positive': 5}  \n",
      "       4         {'negative': 11, 'positive': 6}  \n",
      "       5       {'positive': 215, 'negative': 45}  \n"
     ]
    }
   ],
   "source": [
    "# 5. Run Complete Analysis\n",
    "if __name__ == \"__main__\":\n",
    "    # First install TextBlob if needed\n",
    "    try:\n",
    "        from textblob import TextBlob\n",
    "    except ImportError:\n",
    "        print(\"Installing TextBlob...\")\n",
    "        os.system(\"pip install textblob\")\n",
    "        from textblob import TextBlob\n",
    "    \n",
    "    # Run analysis\n",
    "    analyzed_data = analyze_reviews()\n",
    "    \n",
    "    # Aggregate results\n",
    "    if analyzed_data is not None:\n",
    "        aggregated = aggregate_sentiments(analyzed_data)\n",
    "        if aggregated is not None:\n",
    "            print(\"\\nSample Aggregated Results:\")\n",
    "            print(aggregated.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a51bb780-490b-4adf-9c9d-e9b340477051",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis complete. Sample results:\n",
      "                                              review themes\n",
      "0                                           20 years  Other\n",
      "1  A great app. It's like carrying a bank in your...  Other\n",
      "2                      More than garrantty bank EBC.  Other\n",
      "3  really am happy to this app it is Siple to use...  Other\n",
      "4  I liked this app. But the User interface is ve...  UI/UX\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download(['punkt', 'stopwords', 'wordnet'])\n",
    "\n",
    "# Initialize NLTK\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Define themes\n",
    "themes = {\n",
    "    'Account Access': ['login', 'password', 'account'],\n",
    "    'Transactions': ['transfer', 'payment', 'transaction'],\n",
    "    'App Issues': ['crash', 'error', 'bug', 'slow'],\n",
    "    'UI/UX': ['interface', 'design', 'layout']\n",
    "}\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    return re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "def extract_keywords(text):\n",
    "    tokens = word_tokenize(clean_text(text))\n",
    "    return [lemmatizer.lemmatize(t) for t in tokens if t not in stop_words and len(t) > 2]\n",
    "\n",
    "def assign_themes(text):\n",
    "    keywords = extract_keywords(text)\n",
    "    found = []\n",
    "    for theme, terms in themes.items():\n",
    "        if any(term in keywords for term in terms):\n",
    "            found.append(theme)\n",
    "    return ', '.join(found) if found else 'Other'\n",
    "\n",
    "# Load and process data\n",
    "df = pd.read_csv('cleaned_reviews.csv')\n",
    "df['themes'] = df['review'].apply(assign_themes)\n",
    "df.to_csv('thematic_analysis_results.csv', index=False)\n",
    "\n",
    "print(\"Analysis complete. Sample results:\")\n",
    "print(df[['review', 'themes']].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
